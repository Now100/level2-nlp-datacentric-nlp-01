# 프로젝트 보고서: Data-Centric Topic Classification

---

## 1. 팀 소개 및 프로젝트 개요
### 주제: 데이터 중심 주제 분류
뉴스 헤드라인을 분석해 주제를 분류하는 데 있어, **모델 변경 없이 데이터 가공만으로 성능을 높이는** 방법을 연구. 
별도의 작동 코드는 없으나, 전처리 모듈들과 증강 모듈들을 확실히 클래스화 하여 이후 재사용성을 높임.
구체적으로 본 프로젝트에서는 텍스트와 라벨 노이즈를 식별하고 제거하는 방법, 데이터 증강, 텍스트 정제 등의 접근 방식을 
**Data-Centric**하게 적용하였음.

### 팀원 및 역할
|팀원|역할|
|----|----|
|박준성|----|
|이재백|----|
|강신욱|----|
|홍성균|----|
|백승우|----|
|김정석|----|

### 목표 및 평가 지표
- **목표**: Data-centric 관점에서 데이터의 품질을 개선하여 주제 분류 성능을 높이는 것.
- **평가 지표**:
  - **Macro F1**: 모델 성능의 핵심 지표.
  - **Accuracy**: 참고 지표로 활용.
  
### 데이터 구성
- **Train 데이터**: 2,800개 (1,600개는 텍스트 노이즈 포함, 1,000개는 라벨 노이즈 포함, 200개는 정상)
- **Test 데이터**:
  - Public: 15,000개 (ID, 텍스트만 공개)
  - Private: 15,000개

---

## 2. 프로젝트 진행
### 2.1 텍스트 노이즈 제거
- **텍스트 노이즈 샘플**: "게$판,QK텔d크_아이폰4O아이U}<TyF매 이벤트"와 같은 무작위 아스키 변환을 통해 노이즈가 혼재된 데이터.
- **노이즈 제거 방법**:
  - 텍스트의 50%를 ASCII 랜덤 값으로 변환한 후 LLM을 사용하여 원본 텍스트로 복원.
  - BLEU와 ROUGE 점수를 통해 노이즈 제거 성능 평가. BLEU 점수가 가장 높은 `rtzr/ko-gemma-2-9b-it` 모델을 사용하여 전체 데이터의 노이즈 제거 진행
      - 예시: Y통사 방A~e +증…올.dF4계t첫d추월 -> **이통사 방문객 증… 올해 4월 첫 추월**

### 2.2 라벨 노이즈 처리
- **Cleanlab 라이브러리 활용**:
  - `Cleanlab`의 `find_label_issue` 메서드를 사용하여 self-confidence 값이 낮은 라벨을 노이즈로 판단.
  - **라벨 노이즈 탐지 결과**:
    - LLM으로 교정한 데이터셋을 사용한 경우 `f1: 0.8022` / 라벨 노이즈를 제거한 데이터셋을 사용한 경우 `f1: 0.7918`.
  - **라벨 노이즈 제거 결론**: 정확한 성능을 위해 라벨 노이즈를 제거한 데이터셋을 증강의 기본 데이터셋으로 설정.

- **라벨 교정 (Kiwi 형태소 분석기 + LLM)**:
  - Kiwi 형태소 분석기로 라벨별 주요 형태소 추출하여 LLM에 제공.
  - 라벨별 주요 단어로 프롬프트를 구성해 주어진 텍스트를 0-6 범위의 라벨로 분류하도록 지시하여 라벨 교정 수행.

### 2.3 텍스트 가다듬기
- **텍스트 길이 기준 이상치 제거**:
  - 텍스트 길이를 IQR을 기준으로 이상치를 제거.
- **LLM을 활용한 텍스트 정제**:
  - 노이즈 제거 후 다소 부자연스러운 문장을 LLM으로 재가공.
  - Gemini API를 통해 선택한 텍스트 샘플을 입력하여 텍스트 자연스러움 개선 및 few-shot 학습 방식으로 적용.

### 2.4 데이터 군집화 및 시각화
- **분류기 훈련 후 군집 시각화**:
  - Hugging Face 모델 중 `Leo97/KoELECTRA-small-v3-modu-ner` 모델을 활용하여 라벨 0-6의 범주로 훈련.
  - 훈련된 모델의 CLS 토큰을 기반으로 t-SNE 시각화를 통해 데이터의 군집화 정도 확인.

### 2.5 데이터 증강
- **Back Translation (BT) 및 LLM 증강**:
  - Google과 DeepL을 통한 STS 점수 비교 후 STS가 더 높은 DeepL을 최종 번역기로 사용.
  - 번역의 다양성을 유지하며 주제와 의미를 변형하지 않도록 다각적 기준을 프롬프트에 적용하여 1배 증강 수행.
- **LLM을 활용한 1배 증강**:
  - 문장 내 동의어 교체, 문법적 변형 등을 통해 표현 다양화.
  - 증강 후 EDA를 통해 결측치 및 이상치 제거, 최종적으로 불균형 완화를 위한 라벨 조정.

---

## 3. 피드백 및 교훈
### 피드백
1. **프로그래밍 스타일의 제한**:
   - 객체 지향성을 도입하려 했으나, 코드 복잡성으로 인해 효율성이 감소. 데이터 중심 프로젝트에서는 소프트웨어 설계 원칙을 제한적으로 적용해야 함을 인지.
   
2. **데이터 버전 관리 미흡**:
   - 데이터셋 중복 훈련, 미완성 데이터셋 사용 등 관리 부족. 이를 개선하기 위해 DVC 등의 데이터 버전 관리 도구 사용 필요성 제기.

3. **LLM의 활용 부족**:
   - Rule-based 방법에 지나치게 의존하여, LLM의 잠재력을 충분히 발휘하지 못함.
   - 프롬프트 엔지니어링을 더 세밀히 설정하여 LLM을 적극 활용할 필요가 있음.

4. **기본 EDA 자동화 미흡**:
   - 데이터 길이, 라벨 균형 등을 자동화하여 EDA 수행이 가능하도록 템플릿화 부족. 이로 인해 데이터 정제 중 라벨 누락 등의 실수가 발생.

### 성과
- **모듈화**:
  - Noise Detector, Noise Converter, Label Corrector, Data Augmentor 등의 모듈화 작업을 통해 각기 다른 증강, 라벨 교정, 노이즈 제거 방식을 손쉽게 적용 가능하도록 구현.
  
- **협업 도구 활용**:
  - **Git**을 통한 개인 작업 및 Merge 세션 진행
  - **Notion**으로 실험 상황 및 서버 현황 공유.
  - **Zoom**을 통해 피드백 및 실시간 회의로 협업 강화.

---

## 4. 마무리
|| Accuracy     | Macro F-1     |
|---|--------|--------|
최종| **0.8317** | **0.8265** |
초기| 0.6107 | 0.6179 |

- **최종 데이터셋 구성**: 8,400개 증강 데이터로 최종 학습 데이터 구성.
- **모델 성능 향상**: 텍스트 노이즈 및 라벨 노이즈를 개선한 데이터셋을 바탕으로 분류 성능 향상.

데이터 중심적인 접근 방식을 통해 주제 분류 모델의 성능을 극대화하고, 노이즈 제거 및 증강을 통해 데이터의 크게 개선.
